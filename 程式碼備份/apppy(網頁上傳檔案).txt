# -*- coding: utf-8 -*-
import io
import math
import re
import unicodedata
import difflib
import hashlib
import pandas as pd
import streamlit as st

from attendance_utils import (
    extract_employee_records,  # å–å¾—æ¯æ—¥å‡ºå‹¤ç´€éŒ„ï¼ˆdate, in, out, minutesï¼‰
    extract_pay_items,         # ä¾å§“åå¾å·¥ä½œè¡¨3å–ä¹é …ï¼ˆè‡ªå‹•ç•¥é 0ï¼‰
    fmt_ntd,                   # NT$ åƒåˆ†ä½æ ¼å¼åŒ–
    parse_ntd,                 # è§£æ NT$ æˆ–æ•¸å­—ç‚º int
)

from config import (
    FILE_PATH, SHEET_ATTEND,
    START_COL, DATE_ROW_INDEX, GROUP_STRIDE,
    SHEET_SUMMARY, SUMMARY_FIELDS, SUMMARY_NAME_COL_INDEX,
    SHEET_BONUS, BONUS_FIELD, BONUS_COL_INDEX,
    PDF_FONT_CANDIDATES,      # â† ç”¨æ–¼ä¸­æ–‡å­—å‹è¨»å†Š
)

# =============== PDF ç›¸é—œï¼ˆreportlabï¼‰==============
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont


# ---- Step 1ï¼šè³‡æ–™ä¾†æºæŠ½è±¡ï¼ˆä¿ç•™ï¼›Step 2 æœƒæŠŠä¸Šå‚³æª”æ³¨å…¥é€™è£¡ï¼‰----
if "excel_bytes" not in st.session_state:
    st.session_state["excel_bytes"] = None   # æ”¾ä¸Šå‚³æª” bytesï¼›None ä»£è¡¨ç”¨é è¨­æª”
if "source_label" not in st.session_state:
    st.session_state["source_label"] = f"é è¨­æª”ï¼š{FILE_PATH}"

def get_active_excel_file() -> io.BytesIO | str:
    """å›å‚³ç›®å‰ç”Ÿæ•ˆçš„ Excel ä¾†æºï¼ˆBytesIO æˆ– æª”æ¡ˆè·¯å¾‘ï¼‰ã€‚"""
    if st.session_state.get("excel_bytes") is not None:
        return io.BytesIO(st.session_state["excel_bytes"])
    return FILE_PATH

def get_active_source_label() -> str:
    """é¡¯ç¤ºç›®å‰è³‡æ–™ä¾†æºæ¨™ç±¤ã€‚"""
    return st.session_state.get("source_label", f"é è¨­æª”ï¼š{FILE_PATH}")

def get_excel_cache_key() -> str:
    """çµ¦ cache ç”¨çš„ keyï¼šä¸Šå‚³æª”ç”¨å…¶ md5ï¼›é è¨­æª”ç”¨å›ºå®šå­—ä¸²ã€‚"""
    if st.session_state.get("excel_bytes") is not None:
        md5 = hashlib.md5(st.session_state["excel_bytes"]).hexdigest()
        return f"upload:{md5}"
    return f"default:{FILE_PATH}"


# ------------------ å…±ç”¨å·¥å…· ------------------
def _register_cjk_font() -> str:
    """å˜—è©¦è¨»å†Š CJK å­—å‹ï¼Œå›å‚³è¨»å†Šå¾Œçš„å­—å‹åç¨±ï¼›è‹¥å¤±æ•—å‰‡å›å‚³ 'Helvetica'ã€‚"""
    for path in PDF_FONT_CANDIDATES:
        try:
            pdfmetrics.registerFont(TTFont("CJK", path))
            return "CJK"
        except Exception:
            continue
    return "Helvetica"

def _norm_name(s: str) -> str:
    if s is None:
        return ""
    s = unicodedata.normalize("NFKC", str(s))
    s = s.replace("\u00A0", "").replace("\u3000", "")
    s = re.sub(r"\s+", "", s)
    s = s.replace("\u200b", "").replace("\ufeff", "")
    return s.strip()

def _series_norm(sr: pd.Series) -> pd.Series:
    return sr.astype(str).map(_norm_name)


# ------------------ æª¢æ ¸ï¼šç¢ºèªä¸Šå‚³æª” Schema ------------------
def _match_sheet_name(xls: pd.ExcelFile, target: str, fallback_index: int | None) -> str | None:
    """ä»¥ã€å»ç©ºç™½æ¯”å°ã€å°‹æ‰¾åˆ†é ï¼Œä¸åˆæ™‚å¯é€€å› fallback_index æŒ‡å®šçš„åˆ†é åç¨±ã€‚"""
    if target in xls.sheet_names:
        return target
    norm = lambda s: str(s).strip().replace(" ", "")
    candidates = [s for s in xls.sheet_names if norm(s) == norm(target)]
    if candidates:
        return candidates[0]
    if fallback_index is not None and len(xls.sheet_names) > fallback_index:
        return xls.sheet_names[fallback_index]
    return None

def _validate_summary_sheet(xls: pd.ExcelFile) -> tuple[bool, str]:
    name = _match_sheet_name(xls, SHEET_SUMMARY, fallback_index=2)
    if not name:
        return False, f"æ‰¾ä¸åˆ°ã€{SHEET_SUMMARY}ã€ï¼Œä¸”æ²’æœ‰å¯é€€å›çš„ç¬¬ 3 å€‹åˆ†é ã€‚"
    # å˜—è©¦ header=1 / 0
    for h in (1, 0):
        try:
            df = pd.read_excel(xls, sheet_name=name, header=h)
            cols = [str(c).strip() for c in df.columns]
            if all(field in cols for field in SUMMARY_FIELDS):
                return True, ""
        except Exception as e:
            return False, f"è®€å–æ‘˜è¦åˆ†é å¤±æ•—ï¼š{e}"
    return False, f"æ‘˜è¦åˆ†é ã€{name}ã€ç¼ºå°‘æ¬„ä½ï¼š{[f for f in SUMMARY_FIELDS if f not in cols]}"

def _validate_attend_sheet(xls: pd.ExcelFile) -> tuple[bool, str]:
    name = _match_sheet_name(xls, SHEET_ATTEND, fallback_index=None)
    if not name:
        return False, f"æ‰¾ä¸åˆ°ã€{SHEET_ATTEND}ã€ã€‚"
    try:
        df = pd.read_excel(xls, sheet_name=name, header=1)  # ä½ ç¾æœ‰é‚è¼¯ï¼šheader=1 æœ‰è¡¨é ­
        if df.shape[1] < 2:
            return False, "å‡ºå‹¤åˆ†é æ¬„æ•¸ç•°å¸¸ã€‚"
        a = df.iloc[:, 0].dropna().astype(str).str.strip()
        if a.empty:
            return False, "å‡ºå‹¤åˆ†é  A æ¬„ï¼ˆå§“åï¼‰ç‚ºç©ºã€‚"
        return True, ""
    except Exception as e:
        return False, f"è®€å–å‡ºå‹¤åˆ†é å¤±æ•—ï¼š{e}"

def _find_bonus_col(df: pd.DataFrame) -> int | None:
    """èˆ‡ä¸»ç¨‹å¼åŒåé‚è¼¯ï¼šåœ¨æ¬„åæˆ–å‰ 40 åˆ—å…§æ‰¾ã€çé‡‘ç¸½å’Œ/çé‡‘/bonus/ç·Šæ€¥ã€ã€‚"""
    keywords = ["çé‡‘ç¸½å’Œ", "çé‡‘", "bonus", "ç·Šæ€¥"]
    cols_norm = [str(c).strip().lower() for c in df.columns]
    for k in keywords:
        k = k.lower()
        for idx, cname in enumerate(cols_norm):
            if k in cname and cname != "false":
                return idx
    R = min(40, len(df))
    C = len(df.columns)
    for r in range(R):
        for c in range(C):
            s = str(df.iloc[r, c]).strip().lower()
            if not s:
                continue
            for k in keywords:
                if k in s:
                    return c
    return None

def _validate_bonus_sheet(xls: pd.ExcelFile) -> tuple[bool, str]:
    name = _match_sheet_name(xls, SHEET_BONUS, fallback_index=1)
    if not name:
        return False, f"æ‰¾ä¸åˆ°ã€{SHEET_BONUS}ã€ï¼Œä¸”æ²’æœ‰å¯é€€å›çš„ç¬¬ 2 å€‹åˆ†é ã€‚"
    try:
        # header=1 / 0 çš†è©¦ï¼›åªè¦èƒ½æ‰¾åˆ°çé‡‘æ¬„å³å¯
        for h in (1, 0):
            df = pd.read_excel(xls, sheet_name=name, header=h)
            c = _find_bonus_col(df)
            if c is not None:
                return True, ""
        return False, "çé‡‘åˆ†é æœªåµæ¸¬åˆ°ã€çé‡‘ç¸½å’Œã€æ¬„ä½ï¼ˆæˆ–é—œéµå­—ï¼‰ã€‚"
    except Exception as e:
        return False, f"è®€å–çé‡‘åˆ†é å¤±æ•—ï¼š{e}"

def validate_schema(xls: pd.ExcelFile) -> tuple[bool, list[str]]:
    """ç¸½æª¢æ ¸ï¼šä¸‰å€‹åˆ†é çš†é€šéæ‰ç®—æˆåŠŸã€‚å›å‚³ (ok, problems[])ã€‚"""
    problems: list[str] = []
    ok1, msg1 = _validate_attend_sheet(xls)
    ok2, msg2 = _validate_bonus_sheet(xls)
    ok3, msg3 = _validate_summary_sheet(xls)
    if not ok1: problems.append(f"[å‡ºå‹¤] {msg1}")
    if not ok2: problems.append(f"[çé‡‘] {msg2}")
    if not ok3: problems.append(f"[æ‘˜è¦] {msg3}")
    return (len(problems) == 0, problems)


# ------------------ å®¹éŒ¯è®€å– å·¥ä½œè¡¨3ï¼ˆæ‘˜è¦/ä¹é …ï¼‰ ------------------
@st.cache_data(show_spinner=False)
def _read_summary_sheet(excel_key: str, verbose: bool = False) -> pd.DataFrame | None:
    try:
        xls = pd.ExcelFile(get_active_excel_file())
        sheet_name = SHEET_SUMMARY
        # å»ç©ºç™½æ¯”å° / fallback ç¬¬ 3 å€‹åˆ†é 
        if sheet_name not in xls.sheet_names:
            norm = lambda s: str(s).strip().replace(" ", "")
            candidates = [s for s in xls.sheet_names if norm(s) == norm(sheet_name)]
            if candidates:
                sheet_name = candidates[0]
            elif len(xls.sheet_names) >= 3:
                sheet_name = xls.sheet_names[2]
            else:
                return None

        def _load_with_header(h):
            df = pd.read_excel(xls, sheet_name=sheet_name, header=h)
            df.columns = df.columns.map(lambda s: str(s).strip())
            try:
                col = df.iloc[:, SUMMARY_NAME_COL_INDEX].astype("object")
                df.iloc[:, SUMMARY_NAME_COL_INDEX] = col.astype(str).str.strip()
            except Exception:
                pass
            if False in df.columns:  # å¶ç™¼å¸ƒæ—æ¬„
                df = df.drop(columns=[False])
            return df

        df_sum = _load_with_header(1)
        if not any(col in df_sum.columns for col in SUMMARY_FIELDS):
            df_sum = _load_with_header(0)
        return df_sum
    except Exception:
        return None


# ------------------ è®€å–å·¥ä½œè¡¨2ï¼ˆçé‡‘ï¼‰ ------------------
@st.cache_data(show_spinner=False)
def _read_bonus_sheet(excel_key: str, verbose: bool = False) -> pd.DataFrame | None:
    try:
        xls = pd.ExcelFile(get_active_excel_file())
        sheet_name = SHEET_BONUS
        # å»ç©ºç™½æ¯”å° / fallback ç¬¬ 2 å€‹åˆ†é 
        if sheet_name not in xls.sheet_names:
            norm = lambda s: str(s).strip().replace(" ", "")
            candidates = [s for s in xls.sheet_names if norm(s) == norm(sheet_name)]
            if candidates:
                sheet_name = candidates[0]
            elif len(xls.sheet_names) >= 2:
                sheet_name = xls.sheet_names[1]
            else:
                return None

        def _load(h):
            df = pd.read_excel(xls, sheet_name=sheet_name, header=h)
            df.columns = df.columns.map(lambda s: str(s).strip())
            if False in df.columns:
                df = df.drop(columns=[False])
            return df

        df_bonus = _load(1)
        if df_bonus.shape[1] <= BONUS_COL_INDEX:
            df_bonus = _load(0)
        return df_bonus
    except Exception:
        return None


def _guess_name_col_in_bonus(df_bonus: pd.DataFrame, att_names: set[str], verbose: bool=False) -> int | None:
    att_norm = {_norm_name(x) for x in att_names if x is not None}
    best_i, best_hit = None, -1
    for i in range(len(df_bonus.columns)):
        col_vals = _series_norm(df_bonus.iloc[:, i])
        hit = col_vals.isin(att_norm).sum()
        if hit > best_hit:
            best_i, best_hit = i, hit
    return best_i if best_hit > 0 else None

def _find_bonus_col_for_runtime(df: pd.DataFrame, verbose: bool=False) -> int | None:
    """åŸ·è¡ŒæœŸæ‰¾çé‡‘æ¬„ï¼ˆèˆ‡æª¢æ ¸å…±ç”¨æ€è·¯ï¼‰ã€‚"""
    return _find_bonus_col(df)

def _find_row_anywhere_by_name(df_bonus: pd.DataFrame, target_norm: str, min_ratio: float = 0.70):
    best = None
    R, C = df_bonus.shape
    for c in range(C):
        col_norm = _series_norm(df_bonus.iloc[:, c].astype(str))
        idx = col_norm[col_norm == target_norm].index
        if len(idx) > 0:
            r = int(idx[0])
            raw = df_bonus.iloc[r, c]
            return (r, c, str(raw), 1.0)
    for r in range(R):
        row = df_bonus.iloc[r, :]
        for c in range(C):
            raw = str(row.iloc[c])
            nm = _norm_name(raw)
            if not nm:
                continue
            ratio = difflib.SequenceMatcher(None, target_norm, nm).ratio()
            if best is None or ratio > best[0]:
                best = (ratio, r, c, raw)
    if best and best[0] >= min_ratio:
        ratio, r, c, raw = best
        return (r, c, raw, ratio)
    return None

def _get_bonus_by_name(df_bonus: pd.DataFrame, target: str, att_names: set[str],
                       verbose: bool = False) -> int | None:
    """çµ±ä¸€ç°½åï¼ˆå« verboseï¼‰ï¼Œé¿å…å‘¼å«ç«¯åƒæ•¸ä¸ä¸€è‡´ã€‚"""
    if df_bonus is None:
        return None
    name_col = _guess_name_col_in_bonus(df_bonus, att_names, verbose)
    target_norm = _norm_name(target)
    r = None

    if name_col is not None:
        names_norm = _series_norm(df_bonus.iloc[:, name_col].astype(str))
        idx = names_norm[names_norm == target_norm].index
        if len(idx) > 0:
            r = int(idx[0])

    if r is None:
        C = df_bonus.shape[1]
        found = False
        for c_try in range(C):
            col_norm = _series_norm(df_bonus.iloc[:, c_try].astype(str))
            idx = col_norm[col_norm == target_norm].index
            if len(idx) > 0:
                r = int(idx[0])
                name_col = c_try
                found = True
                break

        if not found:
            hit = _find_row_anywhere_by_name(df_bonus, target_norm, min_ratio=0.70)
            if hit is not None:
                r, name_col, raw_cell, ratio = hit
            else:
                return None

    c = _find_bonus_col_for_runtime(df_bonus, verbose)
    if c is None:
        c = BONUS_COL_INDEX

    if r < 0 or r >= len(df_bonus) or c < 0 or c >= len(df_bonus.columns):
        return None

    val = df_bonus.iloc[r, c]
    if val is None or (isinstance(val, float) and math.isnan(val)):
        return None
    n = parse_ntd(val)
    return n if n != 0 else None


# ------------------ PDF ç”¢ç”Ÿ ------------------
def build_pdf(employee: str, total_min: int | None, records: list[dict],
              bonus_amt: int | None, pay_items: dict) -> bytes:
    buf = io.BytesIO()
    font_name = _register_cjk_font()

    doc = SimpleDocTemplate(
        buf, pagesize=A4,
        leftMargin=28, rightMargin=28, topMargin=28, bottomMargin=28
    )

    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name="TitleCJK", fontName=font_name, fontSize=18, leading=22, spaceAfter=10))
    styles.add(ParagraphStyle(name="H2CJK", fontName=font_name, fontSize=14, leading=18, spaceAfter=8))
    styles.add(ParagraphStyle(name="BodyCJK", fontName=font_name, fontSize=11, leading=15, spaceAfter=6))

    story = []

    story.append(Paragraph(f"{employee} å‡ºå‹¤å ±è¡¨", styles["TitleCJK"]))
    t_min = total_min or 0
    t_days = len(records)
    t_hours = round(t_min / 60, 2) if total_min is not None else 0.0
    story.append(Paragraph(f"å‡ºå‹¤å¤©æ•¸ï¼š{t_days} å¤©ï¼›ç¸½åˆ†é˜æ•¸ï¼š{t_min:,} åˆ†ï¼›ç´„ {t_hours} å°æ™‚", styles["BodyCJK"]))
    story.append(Spacer(1, 6))

    if records:
        table_data = [["æ—¥æœŸ", "ä¸Šç­", "ä¸‹ç­", "åˆ†é˜"]]
        for r in records:
            table_data.append([r["date"], r["in"], r["out"], f'{r["minutes"]:,}'])
        tbl = Table(table_data, colWidths=[90, 80, 80, 60])
        tbl.setStyle(TableStyle([
            ("FONTNAME", (0, 0), (-1, -1), font_name),
            ("FONTSIZE", (0, 0), (-1, -1), 10),
            ("GRID", (0, 0), (-1, -1), 0.25, colors.grey),
            ("BACKGROUND", (0, 0), (-1, 0), colors.whitesmoke),
            ("ALIGN", (1, 1), (-1, -1), "CENTER"),
            ("ALIGN", (3, 1), (3, -1), "RIGHT"),
            ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
        ]))
        story.append(tbl)
        story.append(Spacer(1, 10))

    story.append(Paragraph("è–ªè³‡æ˜ç´°", styles["H2CJK"]))
    printed_any = False
    if bonus_amt is not None and bonus_amt > 0:
        story.append(Paragraph(f"- {BONUS_FIELD}ï¼š{fmt_ntd(bonus_amt)}", styles["BodyCJK"]))
        printed_any = True
    for key in SUMMARY_FIELDS:
        if key in pay_items:
            story.append(Paragraph(f"- {key}ï¼š{fmt_ntd(pay_items[key])}", styles["BodyCJK"]))
            printed_any = True
    if not printed_any:
        story.append(Paragraph("ï¼ˆæ­¤å“¡å·¥æ²’æœ‰å¯é¡¯ç¤ºçš„è–ªè³‡æ˜ç´°ï¼‰", styles["BodyCJK"]))

    doc.build(story)
    return buf.getvalue()


# ------------------ ä¸» UI ------------------
def main():
    st.set_page_config(page_title="å‡ºå‹¤èˆ‡è–ªè³‡ç¸½è¦½", page_icon="ğŸ—‚ï¸", layout="wide")
    st.title("å‡ºå‹¤èˆ‡è–ªè³‡ç¸½è¦½")

    with st.sidebar:
        st.header("ğŸ“‚ ä¸Šå‚³/åˆ‡æ›è³‡æ–™ä¾†æº")
        uploaded = st.file_uploader("ä¸Šå‚³è–ªè³‡ Excelï¼ˆ.xlsxï¼‰", type=["xlsx"])
        if uploaded is not None:
            try:
                excel_bytes = uploaded.getvalue()
                xls = pd.ExcelFile(io.BytesIO(excel_bytes))
                ok, problems = validate_schema(xls)
                if ok:
                    st.success("âœ… æ ¼å¼æª¢æ ¸é€šéï¼Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•æ¡ç”¨æ­¤æª”æ¡ˆã€‚")
                    if st.button("æ¡ç”¨æ­¤æª”æ¡ˆ", type="primary"):
                        st.session_state["excel_bytes"] = excel_bytes
                        st.session_state["source_label"] = f"ä¸Šå‚³æª”ï¼š{uploaded.name}"
                        st.rerun()
                else:
                    st.error("âŒ æ ¼å¼æª¢æ ¸å¤±æ•—ï¼š")
                    for p in problems:
                        st.write("-", p)
            except Exception as e:
                st.error(f"è®€å–ä¸Šå‚³æª”å¤±æ•—ï¼š{e}")

        if st.button("æ”¹å›é è¨­æª”"):
            st.session_state["excel_bytes"] = None
            st.session_state["source_label"] = f"é è¨­æª”ï¼š{FILE_PATH}"
            st.rerun()

    # é¡¯ç¤ºç›®å‰è³‡æ–™ä¾†æº
    st.caption(f"ç›®å‰è³‡æ–™è¡¨ï¼š{get_active_source_label()}")

    # è®€å·¥ä½œè¡¨1ï¼ˆå‡ºå‹¤ï¼‰â€”â€”é€é active source
    xls_att = pd.ExcelFile(get_active_excel_file())
    df_raw = pd.read_excel(xls_att, sheet_name=SHEET_ATTEND, header=None)
    df_att = pd.read_excel(xls_att, sheet_name=SHEET_ATTEND, header=1)

    # æä¾›ã€Œæƒæ A æ¬„å‰å¹¾åˆ—ã€çš„æ§åˆ¶
    max_rows = len(df_att)
    scan_rows = st.number_input("æƒæ A æ¬„å‰å¹¾åˆ—ï¼ˆäººåï¼‰", min_value=1, max_value=max_rows, value=min(30, max_rows), step=1)

    # å“¡å·¥æ¸…å–®ï¼ˆA æ¬„ï¼‰
    names = df_att.iloc[:scan_rows, 0].dropna().astype(str).str.strip().tolist()
    target = st.selectbox("é¸æ“‡å“¡å·¥å§“å", names, index=0)

    # å‡ºå‹¤ç´€éŒ„
    total_min, records = extract_employee_records(
        df_raw, df_att, target,
        scan_rows=scan_rows,
        start_col=START_COL,
        date_row_index=DATE_ROW_INDEX,
        group_stride=GROUP_STRIDE,
    )

    if total_min is None and not records:
        st.warning("æ‰¾ä¸åˆ°å°æ‡‰è³‡æ–™ï¼")
        return

    # æ¦‚è¦½ metrics
    col_top1, col_top2, col_top3 = st.columns([1,1,1])
    with col_top1:
        st.metric("å‡ºå‹¤å¤©æ•¸", f"{len(records)} å¤©")
    with col_top2:
        st.metric("ç¸½åˆ†é˜æ•¸", f"{(total_min or 0):,} åˆ†")
    with col_top3:
        st.metric("ç¸½æ™‚æ•¸(ç´„)", f"{round((total_min or 0)/60, 2)} å°æ™‚")

    # å‡ºå‹¤æ˜ç´°è¡¨
    if records:
        df_show = pd.DataFrame(records, columns=["date", "in", "out", "minutes"]).rename(
            columns={"date":"æ—¥æœŸ", "in":"ä¸Šç­", "out":"ä¸‹ç­", "minutes":"åˆ†é˜"}
        )
        st.dataframe(df_show, use_container_width=True, hide_index=True)

    st.divider()

    # â”€â”€ è–ªè³‡æ˜ç´°ï¼ˆå·¥ä½œè¡¨2 + å·¥ä½œè¡¨3ï¼‰----
    st.subheader("è–ªè³‡æ˜ç´°")

    # cache keyï¼ˆåˆ‡æ›ä¾†æºæ™‚åˆ·æ–° cacheï¼‰
    excel_key = get_excel_cache_key()

    # è®€å·¥ä½œè¡¨3ï¼ˆä¹é …ï¼‰â€” å®¹éŒ¯è®€è¡¨ + cache
    df_sum = _read_summary_sheet(excel_key, False)
    if df_sum is None:
        pay_items = {}
    else:
        try:
            pay_items = extract_pay_items(df_sum, target, SUMMARY_FIELDS)
        except Exception:
            pay_items = {}

    # è®€å·¥ä½œè¡¨2ï¼ˆçé‡‘ï¼‰â€” å®¹éŒ¯è®€è¡¨ + cache
    df_bonus = _read_bonus_sheet(excel_key, False)
    att_names = set(_series_norm(df_att.iloc[:, 0]))
    bonus_amt = _get_bonus_by_name(df_bonus, target, att_names, False) if df_bonus is not None else None

    printed_any = False
    if bonus_amt is not None and bonus_amt > 0:
        st.markdown(f"- **{BONUS_FIELD}**ï¼š{fmt_ntd(bonus_amt)}")
        printed_any = True
    for key in SUMMARY_FIELDS:
        if key in pay_items:
            st.markdown(f"- **{key}**ï¼š{fmt_ntd(pay_items[key])}")
            printed_any = True
    if not printed_any:
        st.info("æ­¤å“¡å·¥æ²’æœ‰å¯é¡¯ç¤ºçš„è–ªè³‡æ˜ç´°ï¼ˆä¹é …çš†ç‚º 0ï¼Œä¸”æœªæ‰¾åˆ°æœ‰æ•ˆçé‡‘ï¼‰ã€‚")

    # ===== ä¸‹è¼‰ PDF æŒ‰éˆ•ï¼ˆåŒ…å«è–ªè³‡æ˜ç´°ï¼‰=====
    pdf_bytes = build_pdf(
        employee=target,
        total_min=total_min,
        records=records,
        bonus_amt=bonus_amt,
        pay_items=pay_items
    )
    st.download_button(
        label="â¬‡ï¸ ä¸‹è¼‰ PDF å ±è¡¨",
        data=pdf_bytes,
        file_name=f"{target}_å‡ºå‹¤å ±è¡¨.pdf",
        mime="application/pdf"
    )


if __name__ == "__main__":
    main()
